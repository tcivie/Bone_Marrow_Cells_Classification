{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqIEMRWhHqe8CxvKX0mcCu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcivie/Bone_Marrow_Cells_Classification/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define constants for the project"
      ],
      "metadata": {
        "id": "eitroYkMCEqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from subprocess import Popen, PIPE\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os"
      ],
      "metadata": {
        "id": "IzrlwxnrDKNJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3dpbmhEKAdP5"
      },
      "outputs": [],
      "source": [
        "CATEGORIES = [\"ABE\", \"ART\", \"BAS\", \"BLA\", \"EBO\", \"EOS\", \"FGC\", \"HAC\", \"KSC\", \"LYI\", \"LYT\", \"MMZ\", \"MON\", \"MYB\", \"NGB\",\n",
        "              \"NGS\", \"NIF\", \"OTH\", \"PEB\", \"PLM\", \"PMO\"]\n",
        "DATA_PATH = os.path.join(os.getcwd(), 'BM_cytomorphology_data')\n",
        "IMAGE_SIZE = (250, 250)\n",
        "BATCH_SIZE = 32  # How many images to train simultaneously"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define check image script"
      ],
      "metadata": {
        "id": "Ra2zoEAkCLWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkImage(path):\n",
        "    proc = Popen(['mogrify', path], stdout=PIPE, stderr=PIPE)\n",
        "    out, err = proc.communicate()\n",
        "    exitcode = proc.returncode\n",
        "    return exitcode, out, err"
      ],
      "metadata": {
        "id": "gYtVX2BOCSV7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Image filtering script (To filter out any broken images)"
      ],
      "metadata": {
        "id": "JifIzUXLCUMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_corrupted_images():\n",
        "    \"\"\"\n",
        "    Filter corrupted images\n",
        "    :return: number of images filtered\n",
        "    \"\"\"\n",
        "    corrupted_images = 0\n",
        "    total_images = 0\n",
        "    for folder_name in CATEGORIES:\n",
        "        for root, subdirs, files in os.walk(os.path.join(DATA_PATH, folder_name)):\n",
        "            # for file in files:\n",
        "            code, output, error = checkImage(root + '/*.jpg')\n",
        "            if str(code) != \"0\" or str(error, \"utf-8\") != \"\":\n",
        "                for file in re.findall('[A-Z]{3}_.*.jpg', str(error, \"utf-8\")):\n",
        "                    print('Removed:' + os.path.join(root, file))\n",
        "                    corrupted_images += 1\n",
        "                    # Delete corrupted image\n",
        "                    os.remove(os.path.join(root, file))\n",
        "    return corrupted_images, total_images"
      ],
      "metadata": {
        "id": "Qnpq55TUCa-z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define dataset generation function"
      ],
      "metadata": {
        "id": "L78N98EfCc2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_dataset():\n",
        "    \"\"\"\n",
        "    Generate dataset\n",
        "    :return: training dataset and validation dataset\n",
        "    \"\"\"\n",
        "    train_ds, val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        DATA_PATH,\n",
        "        validation_split=0.2,  # How much data in recent to save for validation (20% in our case)\n",
        "        subset=\"both\",  # If return only training data or validation (Or both)\n",
        "        seed=2905,\n",
        "        image_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        label_mode='categorical'\n",
        "    )\n",
        "    return train_ds, val_ds"
      ],
      "metadata": {
        "id": "BlBA0zVWCj9y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define data augmentation model\n"
      ],
      "metadata": {
        "id": "ogS6r-KMCk8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_augmentation_model():\n",
        "    \"\"\"\n",
        "    :return: Defined sequential model that randomly flips the images in horizontally and vertically and rotates the\n",
        "    image with the factor of 0.1\n",
        "    \"\"\"\n",
        "    return keras.Sequential(\n",
        "        [\n",
        "            layers.RandomFlip(\"horizontal_and_vertical\")\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "uYY4aPpoCwaI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define data preprocessing function"
      ],
      "metadata": {
        "id": "V_H6vwAWCxM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocessing(train_ds):\n",
        "    \"\"\"\n",
        "    Augments the training data\n",
        "    :param train_ds: The data to augment\n",
        "    :return: Augmented data\n",
        "    \"\"\"\n",
        "    data_augmentation = gen_augmentation_model()\n",
        "    augmented_train_ds = train_ds.map(\n",
        "        lambda img, label: (data_augmentation(img, training=True), label),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    return augmented_train_ds"
      ],
      "metadata": {
        "id": "6Hs4qCbDC067"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define data creation function"
      ],
      "metadata": {
        "id": "ID-4EYE0C3HB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(input_shape):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    # Entry block\n",
        "    x = layers.Rescaling(1.0 / 255)(inputs)  # Rescale the values for the images to go from 0 to 1\n",
        "    x = layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
        "    x = layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(128, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(len(CATEGORIES), activation=\"softmax\")(x)\n",
        "    # outputs = layers.Activation('softmax')(x)\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "pa3YRjr2C7Nz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define training function"
      ],
      "metadata": {
        "id": "cWxp31FhC9oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_ds, val_ds, epochs=25):\n",
        "    callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\")\n",
        "    ]\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(1e-3),  # (Adaptive Moment Estimation) optimization algorithm\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    model.fit(\n",
        "        train_ds,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks,\n",
        "        validation_data=val_ds\n",
        "    )"
      ],
      "metadata": {
        "id": "if19nQWTDAKd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main"
      ],
      "metadata": {
        "id": "Z1TIFC2jDCJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corrupted_images, total_images_checked = filter_corrupted_images()\n",
        "# print(\"Total corrupted deleted: \" + str(corrupted_images) + \" Total images scanned: \" + str(total_images_checked))\n",
        "train_ds, val_ds = generate_dataset()\n",
        "# plot_images(train_ds, gen_augmentation_model())\n",
        "\n",
        "# Apply data_augmentation to teh training images\n",
        "train_ds = data_preprocessing(train_ds)\n",
        "\n",
        "# Prefetching samples in GPU memory helps maximize GPU utilization\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "model = make_model(input_shape=IMAGE_SIZE + (3,))\n",
        "keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "train_model(model, train_ds, val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "znldeKxHDC8T",
        "outputId": "45ae4d3c-37d6-40b3-8d86-ba57b00ec5a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bc40a2551c92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorrupted_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_images_checked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_corrupted_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(\"Total corrupted deleted: \" + str(corrupted_images) + \" Total images scanned: \" + str(total_images_checked))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot_images(train_ds, gen_augmentation_model())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-1581eed34d83>\u001b[0m in \u001b[0;36mgenerate_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m     train_ds, val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# How much data in recent to save for validation (20% in our case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m         f'Received: color_mode={color_mode}')\n\u001b[1;32m    186\u001b[0m   \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interpolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m   dataset_utils.check_validation_split_arg(\n\u001b[0m\u001b[1;32m    188\u001b[0m       validation_split, subset, shuffle, seed)\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/dataset_utils.py\u001b[0m in \u001b[0;36mcheck_validation_split_arg\u001b[0;34m(validation_split, subset, shuffle, seed)\u001b[0m\n\u001b[1;32m    244\u001b[0m         'If `subset` is set, `validation_split` must be set, and inversely.')\n\u001b[1;32m    245\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msubset\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     raise ValueError('`subset` must be either \"training\" '\n\u001b[0m\u001b[1;32m    247\u001b[0m                      'or \"validation\", received: %s' % (subset,))\n\u001b[1;32m    248\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: `subset` must be either \"training\" or \"validation\", received: both"
          ]
        }
      ]
    }
  ]
}